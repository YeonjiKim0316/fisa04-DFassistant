import streamlit as st
import pandas as pd
import os
from openai import OpenAI
from dotenv import load_dotenv

# Load API key
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@st.cache_data
def load_data():
    return pd.read_excel("AdidasSalesdata.xlsx")

df = load_data()

# ìœ í‹¸: í”„ë¡¬í”„íŠ¸ì— df êµ¬ì¡° ì„¤ëª…
def build_definition():
    cols = ", ".join(df.columns.astype(str))
    return f"DataFrame df with columns: {cols}\n"

st.title("Pandas Query Chatbot ğŸ§ ")

# ì´ˆê¸°í™”
if "history" not in st.session_state:
    st.session_state.history = []

# ì´ì „ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"):
    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ historyì— ì¶”ê°€
    st.session_state.history.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # GPT ìš”ì²­ ì „ status spinner í‘œì‹œ
    with st.status("GPT ìƒì„± ì¤‘..."):
        # API í˜¸ì¶œ: streaming=True ì‚¬ìš©
        messages = [
            {"role": "system", "content": "You are a Pandas code generator."},
            {"role": "system", "content": build_definition()},
        ] + st.session_state.history
        stream = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=200,
            temperature=0.5,
            stream=True,
        )
        # GPT ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ì„±
        assistant_resp = ""
        with st.chat_message("assistant"):
            assistant_resp = st.write_stream(stream)

    # ì‘ë‹µì„ historyì— ì €ì¥
    st.session_state.history.append({"role": "assistant", "content": assistant_resp})

    # GPT ì¶œë ¥ ì½”ë“œë¥¼ í˜¸ìŠ¤íŒ…
    st.code(assistant_resp)

    # ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥
    try:
        result = eval(assistant_resp)
        st.write(result)
    except Exception as e:
        st.error(f"ì½”ë“œ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
